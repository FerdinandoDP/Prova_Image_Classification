{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing libraries and dataset"
      ],
      "metadata": {
        "id": "vZGnmvoLO3mO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZTg0skkG_LrW"
      },
      "outputs": [],
      "source": [
        "# IMPORT\n",
        "import scipy.io as sio\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import torch.utils.data as dataloader\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import shutil\n",
        "import copy\n",
        "import random\n",
        "from random import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_cifar = torchvision.datasets.CIFAR10('/content/Cifar10_root', download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8ImvQOm_ijv",
        "outputId": "9cb89cbd-cabe-42a6-88e0-a726452518a0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/Cifar10_root/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:12<00:00, 13127460.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/Cifar10_root/cifar-10-python.tar.gz to /content/Cifar10_root\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(len(dataset_cifar))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaSZucpA_lbH",
        "outputId": "015085cc-fb78-4184-ecd6-a7fe1ed6aac5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "W8pWjwM4_qHU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhpmCm21_tbg",
        "outputId": "b1844509-84fa-446e-864b-815f5e724e74"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n",
            "True\n",
            "Tesla T4\n",
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation"
      ],
      "metadata": {
        "id": "n7NdXYMF_yY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set, val_set = torch.utils.data.random_split(dataset_cifar, [40000, 10000])"
      ],
      "metadata": {
        "id": "LO6Tfu_t_ws9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "after a random split in 70% and 30% for train and validation we will apply the data augmentation tecnique"
      ],
      "metadata": {
        "id": "WNEQ-mSlPACD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images=[]\n",
        "convert_tensor = transforms.ToTensor()\n",
        "\n",
        "for images,targets in train_set:\n",
        "  train_images.append(convert_tensor(images))\n",
        "  im2 = np.fliplr(images).copy()\n",
        "  train_images.append(convert_tensor(im2))\n",
        "\n",
        "valid_images = []\n",
        "for images,targets in val_set:\n",
        "  valid_images.append(convert_tensor(images))\n",
        "  im2 = np.fliplr(images).copy()\n",
        "  valid_images.append(convert_tensor(im2))"
      ],
      "metadata": {
        "id": "VaWmIPQU_9by"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "after data augmentation we apply a normalization"
      ],
      "metadata": {
        "id": "tTBJ_57XPO0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "norm = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "for elem in train_images:\n",
        "  elem = norm(elem)\n",
        "\n",
        "for elem in valid_images:\n",
        "  elem = norm(elem)"
      ],
      "metadata": {
        "id": "4UaqdT0tADyC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "extraction of classes"
      ],
      "metadata": {
        "id": "sG3H2P5LPWUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target=[]\n",
        "for _,targets in train_set:\n",
        "  target.append(targets)\n",
        "  target.append(targets)\n",
        "\n",
        "target2=[]\n",
        "for _,targets in val_set:\n",
        "  target2.append(targets)\n",
        "  target2.append(targets)"
      ],
      "metadata": {
        "id": "qH8_oKugAFSc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "creation of a Dataset"
      ],
      "metadata": {
        "id": "QS09fYXXPdqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data, targets):\n",
        "        self.data = data\n",
        "        self.targets = targets\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.targets[index]\n",
        "\n",
        "\n",
        "\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "8Q8eNE5QAIQN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = MyDataset(train_images,target)\n",
        "val_data = MyDataset(valid_images,target2)"
      ],
      "metadata": {
        "id": "Y9jXYVfwAMBK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creation of a CNN from scratch"
      ],
      "metadata": {
        "id": "SnubkXjjPh3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CNNfdp(nn.Module):\n",
        "  def __init__(self,num_classes):\n",
        "    super(CNNfdp, self).__init__()\n",
        "    self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=128, kernel_size=3, padding=2)\n",
        "    self.conv_layer2 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=2)\n",
        "    self.conv_layer3 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=2)\n",
        "\n",
        "    self.maxpool_lyr = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.dropout_lyr = nn.Dropout(0.25)\n",
        "\n",
        "    self.fc1 = nn.Linear(12800, 128)\n",
        "    self.fc_final = nn.Linear(128, num_classes)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.maxpool_lyr(F.relu(self.conv_layer1(x)))\n",
        "    x = self.maxpool_lyr(F.relu(self.conv_layer2(x)))\n",
        "    x = self.maxpool_lyr(F.relu(self.conv_layer3(x)))\n",
        "    x= x.view(-1, 12800)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.dropout_lyr(x)\n",
        "    x = self.fc_final(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "31UAopywAOq2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "creation of a Dataloader"
      ],
      "metadata": {
        "id": "D0fVp7JqPlqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Batch_size = 16\n",
        "\n",
        "\n",
        "\n",
        "dataloader_train = DataLoader(train_data, batch_size=Batch_size)\n",
        "dataloader_val = DataLoader(val_data, batch_size=Batch_size)"
      ],
      "metadata": {
        "id": "qikZ7qrKARbO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "VaXRfybqPo3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "learning_rate= 0.01\n",
        "startEpoch =0\n",
        "numEpochs =15\n",
        "model = CNNfdp(10).cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "index =0\n",
        "best_acc = 0\n",
        "best_loss = 1\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "for epochs in range(startEpoch,numEpochs + 1):\n",
        "  modelLoss_train = 0.0\n",
        "  modelAcc_train = 0.0\n",
        "  totalSize = 0\n",
        "  for inputs,target in dataloader_train:\n",
        "    optimizer.zero_grad()\n",
        "    inputs = inputs.type(torch.FloatTensor).cuda()\n",
        "    target = target.cuda()\n",
        "    output = model(inputs)\n",
        "    outp,preds = torch.max(output,1)\n",
        "    loss = criterion(output,target)\n",
        "\n",
        "    modelLoss_train += loss.item()*inputs.size(0)\n",
        "    totalSize += inputs.size(0)\n",
        "    modelAcc_train += torch.sum(preds == target).item()\n",
        "    #print(preds)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    index += 1\n",
        "\n",
        "  modelLoss_epoch_train = modelLoss_train/totalSize\n",
        "  modelAcc_epoch_train = modelAcc_train/totalSize\n",
        "\n",
        "  #salvataggio stato\n",
        "  torch.save(model.state_dict(), '/train_weights.pth')\n",
        "  model.eval()\n",
        "\n",
        "  totalSize_val = 0\n",
        "  modelLoss_val = 0.0\n",
        "  modelAcc_val = 0.0\n",
        "\n",
        "  for inputs,labels in dataloader_val:\n",
        "        inputs = inputs.type(torch.FloatTensor).cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        y = model(inputs)\n",
        "        outp, preds = torch.max(y,1)\n",
        "        lossCNN = criterion(y,labels)\n",
        "\n",
        "        modelLoss_val += lossCNN.item()*inputs.size(0)\n",
        "        totalSize_val += inputs.size(0)\n",
        "        modelAcc_val += torch.sum(preds == labels.data).item()\n",
        "\n",
        "  modelLoss_epoch_val = modelLoss_val/totalSize_val\n",
        "  modelAcc_epoch_val = modelAcc_val/totalSize_val\n",
        "  print('Epoch[%d] Train Acc: %.4f , Loss: %.4f ; Validation Acc: %.4f , Loss: %.4f'%(epochs, modelAcc_epoch_train, modelLoss_epoch_train, modelAcc_epoch_val, modelLoss_epoch_val));\n",
        "\n",
        "  if(modelAcc_epoch_val > best_acc) or (modelAcc_epoch_val == best_acc and modelLoss_epoch_val < best_loss):\n",
        "        print('..... Saving best weights ....')\n",
        "        best_acc = modelAcc_epoch_val\n",
        "        best_loss = modelLoss_epoch_val\n",
        "        best_epoca = epochs\n",
        "\n",
        "        torch.save(model.state_dict(), '/content/best_model_weights.pth')\n",
        "\n",
        "  with open('/content/lossVal.txt', \"a\") as file_object:\n",
        "        file_object.write(str(modelLoss_epoch_val)+ '\\n')\n",
        "\n",
        "  with open('/content/AccVal.txt',\"a\") as file_object:\n",
        "        file_object.write(str(modelAcc_epoch_val)+ '\\n')\n",
        "\n",
        "  with open('/content/lossTrain.txt', \"a\") as file_object:\n",
        "        file_object.write(str(modelLoss_epoch_train)+ '\\n')\n",
        "\n",
        "  with open('/content/AccTrain.txt',\"a\") as file_object:\n",
        "        file_object.write(str(modelAcc_epoch_train)+ '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKAmDOeaAXkf",
        "outputId": "eb2b1156-c6d2-43c6-e3e1-a7fdd0436b52"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch[0] Train Acc: 0.3107 , Loss: 1.8789 ; Validation Acc: 0.4491 , Loss: 1.5366\n",
            "..... Saving best weights ....\n",
            "Epoch[1] Train Acc: 0.4919 , Loss: 1.3897 ; Validation Acc: 0.5406 , Loss: 1.2908\n",
            "..... Saving best weights ....\n",
            "Epoch[2] Train Acc: 0.5830 , Loss: 1.1605 ; Validation Acc: 0.6205 , Loss: 1.0789\n",
            "..... Saving best weights ....\n",
            "Epoch[3] Train Acc: 0.6505 , Loss: 0.9847 ; Validation Acc: 0.6711 , Loss: 0.9417\n",
            "..... Saving best weights ....\n",
            "Epoch[4] Train Acc: 0.6994 , Loss: 0.8526 ; Validation Acc: 0.7023 , Loss: 0.8567\n",
            "..... Saving best weights ....\n",
            "Epoch[5] Train Acc: 0.7388 , Loss: 0.7416 ; Validation Acc: 0.7215 , Loss: 0.8059\n",
            "..... Saving best weights ....\n",
            "Epoch[6] Train Acc: 0.7759 , Loss: 0.6431 ; Validation Acc: 0.7318 , Loss: 0.7774\n",
            "..... Saving best weights ....\n",
            "Epoch[7] Train Acc: 0.8067 , Loss: 0.5535 ; Validation Acc: 0.7407 , Loss: 0.7633\n",
            "..... Saving best weights ....\n",
            "Epoch[8] Train Acc: 0.8378 , Loss: 0.4692 ; Validation Acc: 0.7440 , Loss: 0.7750\n",
            "..... Saving best weights ....\n",
            "Epoch[9] Train Acc: 0.8682 , Loss: 0.3852 ; Validation Acc: 0.7500 , Loss: 0.7903\n",
            "..... Saving best weights ....\n",
            "Epoch[10] Train Acc: 0.8990 , Loss: 0.3028 ; Validation Acc: 0.7527 , Loss: 0.8418\n",
            "..... Saving best weights ....\n",
            "Epoch[11] Train Acc: 0.9254 , Loss: 0.2289 ; Validation Acc: 0.7532 , Loss: 0.9183\n",
            "..... Saving best weights ....\n",
            "Epoch[12] Train Acc: 0.9439 , Loss: 0.1757 ; Validation Acc: 0.7532 , Loss: 1.0218\n",
            "Epoch[13] Train Acc: 0.9511 , Loss: 0.1481 ; Validation Acc: 0.7458 , Loss: 1.1444\n",
            "Epoch[14] Train Acc: 0.9561 , Loss: 0.1273 ; Validation Acc: 0.7511 , Loss: 1.1568\n",
            "Epoch[15] Train Acc: 0.9655 , Loss: 0.1011 ; Validation Acc: 0.7522 , Loss: 1.2138\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "gi24WQFRPzdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we will download the test set"
      ],
      "metadata": {
        "id": "Ga9XExhiP21n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = torchvision.datasets.CIFAR10('/content/Cifar10_root', train=False)"
      ],
      "metadata": {
        "id": "VvMLuDetAdsi"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "now we apply to the test images the same operation that we applied to the train and validation sets"
      ],
      "metadata": {
        "id": "-LiXFxXtP8Mx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_images=[]\n",
        "convert_tensor = transforms.ToTensor()\n",
        "for images,targets in test_data:\n",
        "  test_images.append(convert_tensor(images))"
      ],
      "metadata": {
        "id": "pLnYykp4Ae0n"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "norm = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "for elem in test_images:\n",
        "  elem = norm(elem)"
      ],
      "metadata": {
        "id": "EBK8w_D0AhJQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_t=[]\n",
        "for _,targets in test_data:\n",
        "  target_t.append(targets)\n",
        ""
      ],
      "metadata": {
        "id": "NxQiI7BEAjpg"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_set = MyDataset(test_images,target_t)\n",
        "dataloader_test = DataLoader(test_set, batch_size=Batch_size)"
      ],
      "metadata": {
        "id": "O05PP9wiAmyp"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "load the best weights"
      ],
      "metadata": {
        "id": "iNxLyc5NQJ57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_best = CNNfdp(10)\n",
        "model_best.load_state_dict(torch.load('/content/best_model_weights.pth'))\n",
        "model_best.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkrnSKrSAphe",
        "outputId": "65912468-1c1e-42c4-b814-a74e66e0c840"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNNfdp(\n",
              "  (conv_layer1): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
              "  (conv_layer2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
              "  (conv_layer3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
              "  (maxpool_lyr): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (dropout_lyr): Dropout(p=0.25, inplace=False)\n",
              "  (fc1): Linear(in_features=12800, out_features=128, bias=True)\n",
              "  (fc_final): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "totalSize_test = 0\n",
        "modelAcc_test = 0.0\n",
        "\n",
        "for inputs,labels in dataloader_test:\n",
        "        inputs = inputs.type(torch.FloatTensor).cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        y = model(inputs)\n",
        "        outp, preds = torch.max(y,1)\n",
        "        lossCNN = criterion(y,labels)\n",
        "\n",
        "        totalSize_test += inputs.size(0)\n",
        "        modelAcc_test += torch.sum(preds == labels.data).item()\n",
        "\n",
        "modelAcc_epoch_test = modelAcc_test/totalSize_test\n",
        "print('Acc : %.4f'%modelAcc_epoch_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXC1a2Q_Arvn",
        "outputId": "cc1c672e-5af4-47e4-822b-6f1bdfb16a8e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc : 0.7552\n"
          ]
        }
      ]
    }
  ]
}